{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithms import CDAE\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os,sys\n",
    "from scipy.sparse import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(csv_file, shape):\n",
    "    tp = pd.read_csv(csv_file)\n",
    "    rows, cols = np.array(tp['uid']), np.array(tp['sid'])\n",
    "    seq = np.concatenate((rows[:, None], cols[:, None], np.ones((rows.size, 1), dtype='int') ), axis=1)\n",
    "    data = csr_matrix((np.ones_like(rows), (rows, cols)), dtype=np.float32, shape=shape)\n",
    "    return data, seq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/ml-100k/pro'\n",
    "uid_fname = 'unique_uid.txt'\n",
    "sid_fname = 'unique_sid.txt'\n",
    "rating_fname = 'train.csv'\n",
    "test_fname ='test.csv'\n",
    "unique_uid = list()\n",
    "with open(os.path.join(DATA_DIR, uid_fname), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_uid.append(line.strip())\n",
    "unique_sid = list()\n",
    "\n",
    "with open(os.path.join(DATA_DIR, sid_fname), 'r') as f:\n",
    "    for line in f:\n",
    "        unique_sid.append(line.strip())\n",
    "n_items = len(unique_sid)\n",
    "n_users = len(unique_uid)\n",
    "\n",
    "train_data, train_raw = load_data(os.path.join(DATA_DIR, rating_fname),(n_users,n_items))\n",
    "test_data, test_raw = load_data(os.path.join(DATA_DIR, test_fname),(n_users,n_items))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = train_data.todense(),test_data.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(CDAE)\n",
    "\n",
    "model = CDAE.CDAE(n_users, n_items, latent_dim =100, learning_rate = 0.08,\n",
    "                        keep_prob = 0.7, activation = 'sigmoid', use_user_bias = False,lambda_total = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Scale of 0 disables regularizer.\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n",
      "nothing to say for now...\n"
     ]
    }
   ],
   "source": [
    "model.train_model(train_data,vad_data = None,n_iters =100,batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ita/code/recsys/factor-based-recommenderSystems/algorithms/Recommender.py:92: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.nanmean(tmp/k),np.nanmean(tmp/test_data.sum(axis=1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25711253, 0.15050425)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = model.precision_recall_at_k(train_data,test_data,5)\n",
    "ret # (precision and recall at 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
